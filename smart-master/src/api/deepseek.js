import axios from 'axios';

const API_KEY = 'sk-4c93e30ce1af467eb28d8efd7f44e225'; // 请替换为您的实际API密钥
const API_URL = 'https://api.deepseek.com/v1/chat/completions';

/**
 * 调用DeepSeek API生成内容
 * @param {string} prompt - 提示词
 * @param {string} type - 生成类型，'homework'或'lesson_plan'
 * @returns {Promise<string>} 生成的内容
 */
export const generateContent = async (prompt, type) => {
  try {
    // 构建不同类型的系统提示词
    let systemPrompt = '';
    if (type === 'homework') {
      systemPrompt = `你是专业教师助手，根据提供的教学大纲生成课后来练习题目。

            # 练习作业

            ## 填空题
            1. 题目...
            ...（共10道）

            ## 简答题
            1. 题目...
            ...（共5道）`;
    } else if (type === 'lesson_plan') {
      systemPrompt = `
      你是专业教案生成专家，根据提供的教学方向生成完整教案。
      如果用户询问
      1.使用Markdown格式输出，
      2.我将给你提供完整的案例，请你严格仿照这个案例
      3.如果用户输入的与无监督聚类相关话题，请你必须直接返回这个案例一个字都不差，必须返回下面这个案例中的每个字，不要省略字数，我需要很细节的教案
      4.其余知识点请必须仿照这个案例的格式和字数4500字左右，不要省略字数，我需要很细节的教案，一定不要省略
      请务必遵守以上规则
      案例：
      无监督聚类
      教学大纲（课程结构与时间安排）
      0:00–0:10 引入：通过生活中的案例引入聚类概念。例如，讨论手机相册的自动人脸分组功能，提问学生手机是如何在没有姓名标签的情况下将同一人的照片归到一起（互动1）。教师引出"物以类聚，人以群分"的古语，说明相似的人或物会自然聚在一起，这正是聚类的思想。
      0:10–0:20 基本概念：讲解无监督学习与聚类的定义，强调无监督学习不需要预先给定类别标签，算法通过数据内部模式自动发现分组。给出聚类分析的正式定义：在不预先定义类别的情况下，将数据样本划分为若干簇，使同一簇内的数据相似度高，不同簇之间的相似度低。对比监督学习中的分类任务，突出聚类的特点和用途。
      0:20–0:35 聚类算法（K-Means）原理：介绍K-Means（K-均值）聚类算法作为聚类的经典方法。讲解算法步骤：随机初始化k个簇中心；将每个数据点归属到最近的簇中心；重新计算簇中心；迭代重复直到簇不再变化（算法收敛）。强调K-Means试图最小化簇内距离之和，实现簇内点"接近"而簇间点"远离"。说明K值（簇的数量）是算法的超参数，需要在算法开始前给定。
      0:35–0:45 算法示例与互动：通过一个简单示例演示K-Means算法运行过程。教师提供一组二维平面上的点及初始簇中心，引导学生一步步执行算法迭代：计算点到簇中心的距离，将点分配到最近的簇，更新簇中心（互动2）。学生参与计算第一轮迭代的结果，由教师确认答案并进一步讲解后续迭代如何收敛到稳定的聚类结果。讨论影响聚类结果的因素，如初始中心选择和预先确定的K值。
      0:45–0:55 应用拓展与讨论：总结K-Means的适用场景和局限（例如对初始值敏感，需要指定簇数等）。简要介绍其他聚类方法名称（如层次聚类、密度聚类DBSCAN）拓宽视野，但不展开细节。组织学生思考聚类在实际中的应用，让学生举例说明在哪些场景可以采用聚类分析（互动3）。教师点拨并补充典型应用领域，如客户细分、图片聚类、文本话题聚类等，将理论与实践相联系。强调聚类技术已被广泛应用于环境、医学、生物、天文、经济等众多领域，K-Means则是其中应用最为广泛的算法之一。
      0:55–1:00 总结与课后建议：教师梳理本节课的知识结构，回顾聚类的概念、K-Means算法步骤和特点等重点内容，澄清学生提问。总结时再次强调聚类分析的核心思想和"相似对象归于一簇"的原则。提出课后建议：鼓励学生复习本节内容，巩固对关键概念和算法过程的理解；建议对照预习视频中的示例再次手算一遍K-Means迭代过程或尝试使用简单数据运行聚类算法加深理解；留意日常生活或其他课程中是否出现聚类思想的应用，以加深对聚类价值的体会。
      本节课重点掌握知识点
      无监督学习与聚类概念：理解无监督学习的含义和聚类分析的定义，能够解释聚类不依赖预先给定的类别标签，通过发现数据内部模式自动分组。理解"物以类聚，人以群分"的含义，建立生活常识与聚类理论的关联。
      聚类分析的性质：掌握聚类的目标是使同一簇内对象的相似性最大化、不同簇之间相似性最小化。了解聚类结果没有"正确答案"的唯一标准，取决于数据分布和算法参数，需根据任务选择合适的簇数和算法。
      K-Means算法原理与步骤**：重点掌握K-Means聚类算法的工作流程，包括初始化、簇分配、中心更新和迭代收敛。理解K-Means算法的每一步含义：随机选择初始中心，将样本归类到最近中心，计算新的均值作为中心，不断重复。理解收敛判据是簇分配不再变化或达到最大迭代次数。
      K-Means算法的参数和局限：了解K-Means需要人工指定簇数K，K的选择会直接影响聚类结果。知道K-Means对初始中心选择敏感，可能陷入局部最优，需要多次运行取最佳或采用改进的初始化方法。了解K-Means擅长发现球状簇且对噪声和异常值较敏感的局限性。
      聚类算法的应用：认识聚类分析在各领域的广泛应用价值。能够举出至少一个使用聚类的实际案例（例如客户分群、搜索结果聚类等），体会聚类在从海量未标记数据中发现结构模式方面的重要作用。为后续学习更高级的聚类方法或应用打下基础。
      引入环节：生活案例与理论对应
      教师以生活中的照片管理案例引入主题：问学生是否注意过手机相册会自动按人物对照片进行分类。例如，当我们浏览手机相册时，经常会看到手机自动将相同人的照片聚在一起，形成"某人"的相册分类，而这一过程并没有人工手动标记每张照片的人名。教师提问："手机是如何做到在没有提供姓名标签的情况下，就把属于同一人的照片归为一组的呢？"（引发学生思考）。
      学生可能会联想到手机会识别人脸的相似特征。教师进一步解释：手机相册利用人脸识别和聚类算法，根据面部特征的相似程度自动将相似的面孔归类到一起。这其实就是无监督聚类的一个直观例子：不依赖预先的人为标签，完全根据数据（人脸图像）的相似性来分组。正如俗语所说："物以类聚，人以群分"，相似的事物会自然地聚在一起，这句话生动地描述了聚类的思想。通过这个生活案例，学生对"聚类"有了初步感性认识：明白聚类就是让相似的对象归为同一类，而不相似的对象分开。
      接下来，教师顺势引出本节课主题，指出将以该案例为切入点，系统学习无监督聚类的概念和一种经典算法。说明现实中除了照片分组外，聚类还有许多应用场景，下文将逐步揭示其理论与实践。
      （本环节对应理论：日常案例——手机相册人脸分组，对应聚类中"无标签自动分组"的特点。）
      互动环节设计
      互动环节1：手机相册聚类现象讨论
      内容：以手机自动分组照片的案例引出问题，鼓励学生联系常识思考聚类的原理。
      形式：课堂问答讨论。教师提出问题，学生自由发言或与同桌短暂讨论，然后教师总结。
      问题：手机在没有人为标注姓名的情况下，是根据什么来判断哪些照片属于同一个人并将它们聚在一起的？
      答案：手机通过比较人脸的相似特征来分组照片。也就是说，它提取每张照片中人脸的特征向量，计算照片之间的相似度或距离，将特征相似度高的照片归为一簇，认为是同一人。 这一过程不需要提前告诉它谁是谁，正体现了聚类根据数据相似性自动分组的原理。
      （教师总结：手机利用聚类算法，根据面部特征的相似程度自动将照片分组，同类照片特征相似，不同组照片特征差异大。这正是聚类分析"相似的归一起"思想在生活中的应用。）
      互动环节2：K-Means算法手算演练
      内容：在讲解完K-Means算法步骤后，通过一个简化的数值示例让学生参与计算，加深对算法迭代过程的理解。
      形式：课堂练习。教师在黑板或投影上给出少量点的数据集和初始簇中心，学生可分小组计算或个人尝试，随后由教师引导全班一起核对计算过程和结果。
      问题：假设有如下四个数据点，需要使用K-Means将它们聚成2个簇：
      数据点坐标：(1,1)，(2,2)，(9,9)，(10,10)
      初始选择簇中心：C1=(1,1)，C2=(2,2)
      请学生计算：第一轮迭代结束后，各簇包含哪些点？新的簇中心分别是什么？
      答案：按照K-Means算法第一轮：
      簇分配：计算每个点到初始中心的距离，将点分配给最近的中心：
      1.	Point (1,1):
      o	Distance to C₁: 0
      o	Distance to C₂: √[(1-2)² + (1-2)²] = √2 ≈ 1.414
      o	Assignment: Cluster 1
      2.	Point (2,2):
      o	Distance to C₁: √[(2-1)² + (2-1)²] = √2 ≈ 1.414
      o	Distance to C₂: 0
      o	Assignment: Cluster 2
      3.	Point (9,9):
      o	Distance to C₁: √[(9-1)² + (9-1)²] = √128 ≈ 11.314
      o	Distance to C₂: √[(9-2)² + (9-2)²] = √98 ≈ 9.899
      o	Assignment: Cluster 2
      4.	Point (10,10):
      o	Distance to C₁: √[(10-1)² + (10-1)²] = √162 ≈ 12.727
      o	Distance to C₂: √[(10-2)² + (10-2)²] = √128 ≈ 11.314
      o	Assignment: Cluster 2
      分配结果：
      •	Cluster 1: {(1,1)}
      •	Cluster 2: {(2,2), (9,9), (10,10)}
      中心更新：计算每个簇的新中心（即簇内所有点坐标的均值）：
      簇1的新中心：只有(1,1)，均值即(1,1)（中心不变）。
      簇2的新中心：将(2,2)、(9,9)、（10,10)三点的坐标分别取平均。计算x坐标均值：(2 + 9 + 10) / 3 = 21 / 3 = 7；y坐标均值同样=7。因此新中心C_2'=(7,7)。
      第一轮迭代完成后，簇1包含点(1,1)，中心为(1,1)；簇2包含点(2,2)、(9,9)、(10,10)，新计算得到的中心为(7,7)。
      （教师继续讲解：可以看到由于初始两个中心选得太接近，第一轮簇2一口气吸收了三个点，新的中心移动到了(7,7)。接下来第二轮迭代中，(2,2),会更靠近新的C1'(1,1)还是C2'(7,7)？学生可以预期(2,2),会转移到簇1。教师快速演示第二轮：新的簇1将有(1,1)和(2,2),，中心变为(1.5,1.5)，簇2有(9,9)和(10,10)，中心变为(9.5,9.5)。第三轮分配不再变化，算法收敛。通过此演练，学生直观理解了K-Means通过反复迭代逐步稳定分组的过程。)
      互动环节3：聚类应用头脑风暴
      内容：在课程后半段，启发学生将所学知识与现实问题相联系，讨论聚类技术可以应用的场景。
      形式：头脑风暴式开放问答。教师提出问题后，学生思考片刻并自由发言分享想法。教师对学生给出的例子进行点评和引申。
      问题：除了手机相册的人脸分组，你还能举出哪些现实中的场景或应用可以使用聚类分析？换言之，哪些情况下我们需要在没有现成分类标签的海量数据中自动发现类别？
      答案：此问题开放性较强，学生答案可能多种多样。教师根据学生回答进行总结，强调以下典型应用：
      客户分群：例如电商或银行根据用户的消费行为数据，将具有相似消费习惯的客户自动归为一类，用于精准营销。
      图片聚类：将大量未标注的图片按内容相似度分组，例如把风景照、人物照、动物照自动分类，方便整理或用于建立图库。
      新闻文本聚类：新闻聚合网站会自动将内容相近的新闻文章归为一组，方便用户浏览同一事件的不同报道。
      基因聚类：在生物信息学中，根据基因表达数据将功能相似的基因归类，有助于发现基因功能模块。
      异常检测：利用聚类找出"不属于任何一簇"的离群点，例如信用卡交易中与任何群组都差异很大的记录可能是异常行为。
      （以上只是部分示例，学生的其他合理答案如社交媒体用户分群（按兴趣爱好）、商品聚类（根据销售特征自动归类库存）等都可以接受。教师通过这些例子强调：聚类适用于任何需要从无标签数据中发现自然分类结构的情况，帮助我们从海量数据中提取有意义的分组信息。）
      总结环节（知识梳理与课后建议）
      知识结构梳理：教师在黑板或投影展示本节课的知识要点框架，再次梳理主要内容：
      概念复习：要求一名学生用自己的话解释什么是聚类，另一名学生解释何为无监督学习，以巩固定义。如果有困难，教师协助补充：无监督学习是在没有标签指导的情况下让算法自行从数据中找结构，聚类是无监督学习的重要任务，其目标是让同类对象高相似度聚在一起。
      方法回顾：提问学生K-Means算法的核心步骤（初始化中心、分配样本、更新中心、迭代）是否清楚，每一步的目的是什么。教师归纳：K-Means通过不断优化簇内紧密程度来分配数据，它简单高效，是应用最广的聚类算法之一 (K-means算法研究综述_k-means算法是统计方法吗?-CSDN博客)。同时提醒它需要指定簇数K且对初始值敏感。这部分教师可以列出简洁的流程图或要点列表，加深印象。 
      重点强化：再次强调"相似度"在聚类中的关键作用，聚类效果取决于我们对相似度的度量（本节隐含采用欧氏距离作为相似度度量）。聚类得到的是数据内部的一种结构假设，需要结合领域知识判断其意义。例如，手机分组照片得到的是"可能是同一个人"的簇，实际还需人为确认名字。
      课后拓展建议：
      预习回顾：学生可再次观看或回顾课前推荐的视频，加深对聚类概念和K-Means过程的理解。特别建议重温视频中的手算示例，与课堂演示相对照，确保每一步都搞清楚（例如距离计算、重新分配簇和计算新中心的过程）。
      动手实践：有条件的同学可以尝试在电脑上使用现成工具或编程库（如Python的scikit-learn）对一个简单数据集进行聚类分析，把理论付诸实践。在实践中观察改变簇数K或初始种子对结果的影响，巩固对K-Means特性的认识。
      拓展阅读：对聚类感兴趣的同学，可阅读教材或网上资料中关于其他聚类方法的章节，例如层次聚类如何构建簇的树状结构，密度聚类如何根据点密度发现任意形状的簇。这些内容超出本节课但有助于拓展视野。 
      观察思考：鼓励学生留心生活或专业领域的数据分类问题，思考哪些可以看作聚类任务。例如，音乐推荐是否可以通过分析听歌模式来自动分群？这样不断将课堂所学与现实联系，有助于加深对知识的掌握和应用。课堂群交流平台也将开放讨论帖，供大家分享自己发现的聚类应用案例，相互启发。
      本次课的教案到此结束，希望通过本节学习，学生对无监督聚类有了系统的认识，并为后续更深入的机器学习课程打下基础。同学们课后可按照上述建议进一步巩固和拓展，对聚类保持好奇心和探索精神。



`;
    }

    // 实际调用DeepSeek API
    console.log('调用DeepSeek API:', { type });
    
    const response = await axios.post(
      API_URL,
      {
        model: 'deepseek-chat',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: prompt }
        ],
        temperature: 0.7,
        max_tokens: 5000
      },
      {
        headers: {
          'Authorization': `Bearer ${API_KEY}`,
          'Content-Type': 'application/json'
        }
      }
    );
    
    // 从API响应中提取内容
    if (response.data && response.data.choices && response.data.choices.length > 0) {
      return response.data.choices[0].message.content;
    } else {
      throw new Error('API返回格式错误');
    }
    
  } catch (error) {
    console.error('API调用失败:', error);
    throw new Error('生成内容失败，请稍后再试');
  }
};
